#!/usr/bin/env node
// AI Scent æ•°æ®å½•å…¥è„šæœ¬
// ç”¨æ³•: npm run ingest

import * as fs from 'fs';
import * as path from 'path';
import { fileURLToPath } from 'url';
import dotenv from 'dotenv';

const __dirname = path.dirname(fileURLToPath(import.meta.url));
const ROOT_DIR = path.resolve(__dirname, '../..');

// ä»é¡¹ç›®æ ¹ç›®å½•åŠ è½½ .env
dotenv.config({ path: path.join(ROOT_DIR, '.env') });

import { crawl } from './crawler.js';
import { analyzeProduct } from './analyzer.js';
import { initDB, insertProduct, getProductBySlug, uploadScreenshot } from './db.js';
import type { IngestConfig, Product } from './types.js';

// è¯»å–å¾…å¤„ç†çš„ URL åˆ—è¡¨
function loadUrls(): IngestConfig[] {
  // ä¼˜å…ˆè¯»å– pending.json
  const pendingPath = path.join(ROOT_DIR, 'pending.json');
  if (fs.existsSync(pendingPath)) {
    const content = fs.readFileSync(pendingPath, 'utf-8');
    return JSON.parse(content);
  }

  // å¤‡é€‰è¯»å– urls.txt
  const urlsPath = path.join(ROOT_DIR, 'urls.txt');
  if (fs.existsSync(urlsPath)) {
    const content = fs.readFileSync(urlsPath, 'utf-8');
    return content
      .split('\n')
      .map(line => line.trim())
      .filter(line => line && !line.startsWith('#'))
      .map(url => ({ url }));
  }

  return [];
}

// å¤„ç†å•ä¸ª URL
async function processUrl(config: IngestConfig): Promise<void> {
  const { url, category, tags } = config;

  console.log(`\nğŸ” Processing: ${url}`);

  try {
    // 1. çˆ¬å–ç½‘é¡µ
    console.log('  ğŸ“¡ Crawling...');
    const crawlResult = await crawl(url);
    console.log(`  âœ“ Title: ${crawlResult.title}`);

    // 2. AI åˆ†æ
    console.log('  ğŸ¤– Analyzing with AI...');
    const analysis = await analyzeProduct(crawlResult);
    console.log(`  âœ“ Name: ${analysis.name}`);
    console.log(`  âœ“ Category: ${analysis.category}`);

    // 3. æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
    const existing = await getProductBySlug(analysis.slug);
    if (existing) {
      console.log(`  âš ï¸  Product "${analysis.slug}" already exists, skipping...`);
      return;
    }

    // 4. ä¸Šä¼ æˆªå›¾ (å¦‚æœæœ‰)
    let screenshotUrl: string | undefined;
    if (crawlResult.screenshot) {
      console.log('  ğŸ“¸ Uploading screenshot...');
      try {
        // å¦‚æœæ˜¯ base64ï¼Œè½¬æ¢ä¸º Buffer
        if (crawlResult.screenshot.startsWith('data:')) {
          const base64Data = crawlResult.screenshot.split(',')[1];
          const buffer = Buffer.from(base64Data, 'base64');
          screenshotUrl = await uploadScreenshot(analysis.slug, buffer);
        } else {
          // å·²ç»æ˜¯ URL
          screenshotUrl = crawlResult.screenshot;
        }
        console.log('  âœ“ Screenshot uploaded');
      } catch (err) {
        console.log('  âš ï¸  Screenshot upload failed, continuing...');
      }
    }

    // 5. æ’å…¥æ•°æ®åº“
    console.log('  ğŸ’¾ Saving to database...');
    const product: Omit<Product, 'id' | 'created_at' | 'updated_at'> = {
      slug: analysis.slug,
      name: analysis.name,
      tagline: analysis.tagline,
      website_url: url,
      logo_url: crawlResult.metadata.favicon || crawlResult.metadata.ogImage,
      screenshot_url: screenshotUrl,
      category: category || analysis.category,
      tags: tags && tags.length > 0 ? tags : analysis.tags,
      ai_analysis: analysis.ai_analysis,
      status: 'draft'
    };

    const inserted = await insertProduct(product);
    console.log(`  âœ… Success: [${inserted.name}] inserted with slug "${inserted.slug}"`);

  } catch (error) {
    console.error(`  âŒ Error: ${error instanceof Error ? error.message : error}`);
  }
}

// ä¸»å‡½æ•°
async function main() {
  console.log('ğŸš€ AI Scent Data Ingestion Script');
  console.log('==================================\n');

  // æ£€æŸ¥ç¯å¢ƒå˜é‡
  const requiredEnvVars = ['SUPABASE_URL', 'SUPABASE_SERVICE_KEY', 'DASHSCOPE_API_KEY'];
  const missing = requiredEnvVars.filter(v => !process.env[v]);

  if (missing.length > 0) {
    console.error(`âŒ Missing environment variables: ${missing.join(', ')}`);
    console.error('Please create a .env file in the project root.');
    process.exit(1);
  }

  // åˆå§‹åŒ–æ•°æ®åº“
  initDB();
  console.log('âœ“ Database connected');

  // åŠ è½½ URL åˆ—è¡¨
  const urls = loadUrls();

  if (urls.length === 0) {
    console.log('\nâš ï¸  No URLs to process.');
    console.log('Create a urls.txt or pending.json file in the project root.');
    console.log('\nExample urls.txt:');
    console.log('  https://midjourney.com');
    console.log('  https://claude.ai');
    console.log('\nExample pending.json:');
    console.log('  [{ "url": "https://midjourney.com", "category": "å›¾åƒ" }]');
    return;
  }

  console.log(`ğŸ“‹ Found ${urls.length} URL(s) to process`);

  // é€ä¸ªå¤„ç†
  for (const config of urls) {
    await processUrl(config);
  }

  console.log('\n==================================');
  console.log('âœ¨ Ingestion complete!');
}

main().catch(console.error);
